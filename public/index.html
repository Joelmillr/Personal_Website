<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Joel Andrew Miller - Aerospace Software Engineer</title>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-PEGHJHV0P5"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag() { dataLayer.push(arguments); }
        gtag('js', new Date());

        gtag('config', 'G-PEGHJHV0P5');
    </script>
    <link rel="stylesheet" href="styles.css">
    <style>
        html {
            scroll-behavior: smooth;
        }
    </style>
</head>

<body>
    <!-- Skip to main content link for accessibility -->
    <a href="#hero" class="skip-link">Skip to main content</a>

    <!-- Navigation -->
    <nav class="navbar" role="navigation" aria-label="Main navigation">
        <div class="nav-content">
            <a href="#hero" class="logo">JAM</a>
            <button class="mobile-menu-toggle" aria-label="Toggle navigation menu" aria-expanded="false">
                <span></span>
                <span></span>
                <span></span>
            </button>
            <ul class="nav-links">
                <li><a href="#about">About</a></li>
                <li><a href="#experience">Experience</a></li>
                <li><a href="#projects">Projects</a></li>
                <li><a href="#drawing">Draw a Number</a></li>
                <li><a href="#contact">Contact</a></li>
                <li><a href="assets/Resume.pdf" target="_blank">Resume</a></li>
            </ul>
        </div>
    </nav>

    <!-- Hero Section -->
    <header id="hero" class="hero">
        <div class="container">
            <div class="hero-content">
                <h1>Joel Andrew Miller</h1>
                <p class="tagline">Machine Learning Engineer | Computer Vision Researcher | Signal Processing Specialist
                </p>
                <hr>
                <div class="cta-buttons">
                    <a href="#featured-project" class="btn primary">View Featured Project</a>
                    <a href="#projects" class="btn secondary">Explore All Research</a>
                    <a href="#contact" class="btn secondary">Let's Connect</a>
                    <a href="assets/Resume.pdf" class="btn primary" target="_blank">Download Resume</a>
                </div>
                <div class="hero-illustrations">
                    <img src="assets/Me_Ghiblified.png" alt="Joel Miller Illustration" class="hero-illustration">
                </div>
            </div>
        </div>
    </header>

    <!-- Featured Research Project: Flight Test Display -->
    <section id="featured-project" class="section">
        <div class="container">
            <h2>Featured Research Project</h2>
            <hr>
            <div class="featured-project retro-box">
                <h3>Helmet-Mounted Display (HMD) VR System for Pilots</h3>
                <p><strong>VR Development & Computer Vision</strong> | 2024-2025</p>
                <p><strong>Tags:</strong> Virtual Reality | Computer Vision | Signal Processing | Real-Time Systems |
                    3D Graphics | Sensor Fusion</p>
                <hr class="dotted">
                <p class="featured-description">
                    A virtual reality helmet-mounted display system for pilots featuring real-time information overlay
                    using computer vision algorithms and signal processing techniques for sensor data fusion. The system
                    processes multi-modal flight sensor data (IMU, GPS, attitude sensors) to provide pilots with
                    real-time flight information, navigation cues, and situational awareness through an immersive VR
                    interface. Built with Godot engine for 3D rendering and VR display, with computer vision algorithms
                    for real-time information overlay and signal processing pipelines for sensor fusion.
                </p>
                <ul class="featured-highlights">
                    <li>Developed VR helmet-mounted display system using computer vision algorithms for real-time
                        information overlay</li>
                    <li>Implemented signal processing pipelines for multi-modal sensor data fusion (IMU, GPS, attitude
                        sensors)</li>
                    <li>Created real-time 3D visualization and HUD elements using Godot engine for immersive pilot
                        experience</li>
                    <li>Built sensor fusion algorithms for accurate vehicle and helmet orientation tracking in VR space
                    </li>
                    <li>Designed first-person VR interface with pitch ladder, heading tape, and altitude/speed displays
                    </li>
                    <li>Developed real-time data processing backend for sensor synchronization and quaternion-based
                        orientation tracking</li>
                </ul>
                <div class="featured-actions">
                    <a href="/webdisplay" class="btn primary" target="_blank" rel="noopener">
                        View Live Demo
                    </a>
                </div>
            </div>
        </div>
    </section>

    <!-- About Me -->
    <section id="about" class="section">
        <div class="container">
            <h2>About Me</h2>
            <hr>
            <div class="about-content">
                <div class="about-text">
                    <p>I am a Machine Learning Engineer and Computer Vision Researcher specializing in signal processing
                        and data-driven solutions. Currently working as an Aerospace Software Engineer at the
                        International Test Pilots School (ITPS) Canada, I develop ML-powered systems for aviation
                        applications, including computer vision algorithms for helmet-mounted displays and signal
                        processing pipelines for real-time sensor data analysis.</p>
                    <p>My research focuses on applying machine learning techniques to physiological signal analysis,
                        computer vision for autonomous systems, and statistical signal processing. I have published work
                        on driver behavior analysis using heart rate signals and have extensive experience building ML
                        pipelines for sensor fusion, image processing, and time-series analysis. My expertise spans deep
                        learning, classical ML algorithms, and signal processing methods applied to real-world problems
                        in transportation and aerospace domains.</p>
                </div>
                <div class="skills-container retro-box">
                    <h3>Core Technical Skills</h3>
                    <ul class="skill-tags">
                        <li>Machine Learning</li>
                        <li>Computer Vision</li>
                        <li>Signal Processing</li>
                        <li>Deep Learning</li>
                        <li>Python</li>
                        <li>TensorFlow/PyTorch</li>
                        <li>Statistical Analysis</li>
                        <li>Sensor Fusion</li>
                        <li>Time-Series Analysis</li>
                        <li>Data Science</li>
                    </ul>
                </div>
            </div>
        </div>
    </section>

    <!-- Experience -->
    <section id="experience" class="section">
        <div class="container">
            <h2>Experience</h2>
            <hr>
            <div class="timeline">
                <div class="timeline-item retro-box">
                    <div class="timeline-date text-green">February 2025 - Present</div>
                    <div class="timeline-content">
                        <h3>Aerospace Software Engineer</h3>
                        <p><strong>International Test Pilots School</strong> - London, Ontario</p>
                        <ul>
                            <li>Leading R&D efforts to develop a helmet-mounted display system using computer vision
                                algorithms for real-time information overlay and signal processing techniques for sensor
                                data fusion</li>
                            <li>Implementing machine learning models for pilot state detection and adaptive display
                                systems</li>
                            <li>Developing signal processing pipelines for multi-modal sensor data (IMU, GPS, video)
                                integration</li>
                        </ul>
                    </div>
                </div>
                <div class="timeline-item retro-box">
                    <div class="timeline-date text-green">September 2023 - December 2023</div>
                    <div class="timeline-content">
                        <h3>R&D Engineering Intern</h3>
                        <p><strong>National Research Council Canada</strong> - London, Ontario</p>
                        <ul>
                            <li>Developed computer vision and signal processing pipelines to transform multi-modal
                                sensor data (LiDAR point clouds, camera images, GPS signals) into simulated environments
                                for autonomous vehicle testing</li>
                            <li>Implemented data preprocessing algorithms for sensor fusion and coordinate
                                transformation using MATLAB and Python</li>
                            <li>Built ML-based data validation and quality assessment tools for sensor data streams</li>
                        </ul>
                    </div>
                </div>
                <div class="timeline-item retro-box">
                    <div class="timeline-date text-green">May 2023 - December 2025</div>
                    <div class="timeline-content">
                        <h3>M.E.Sc Software Engineering</h3>
                        <p><strong>Western University</strong> - London, Ontario</p>
                        <ul>
                            <li>Research focus: Machine learning and signal processing for autonomous vehicle systems
                            </li>
                            <li>Developing ML models for driver state detection using physiological signal analysis
                                (heart rate, EEG, eye-tracking)</li>
                            <li>Applying statistical signal processing methods (E-Tests, Poisson modeling) to analyze
                                driver behavior patterns</li>
                            <li>Published first-author research on signal processing applications in transportation
                                (Springer Nature, 2025)</li>
                            <li>Part of the AiX Lab (AI & Autonomous Systems) and EMRC Lab (Engineering & Machine
                                Learning Research)</li>
                        </ul>
                    </div>
                </div>
                <div class="timeline-item retro-box">
                    <div class="timeline-date text-green">May 2021 - September 2022</div>
                    <div class="timeline-content">
                        <h3>Software Engineer / DevOps Intern</h3>
                        <p><strong>IBM</strong> - Markham, Ontario</p>
                        <ul>
                            <li>Developed automated testing frameworks for IBM's Order Management System (OMS)</li>
                            <li>Built frontend components and Dockerized virtual machines for test case execution and
                                monitoring</li>
                            <li>Mentored new interns and worked with Angular, Docker</li>
                        </ul>
                    </div>
                </div>
                <div class="timeline-item retro-box">
                    <div class="timeline-date text-green">September 2018 - April 2023</div>
                    <div class="timeline-content">
                        <h3>B.E.Sc Software Engineering with IBM Coop</h3>
                        <p><strong>Western University</strong> - London, Ontario</p>
                        <ul>
                            <li>Completed my undergraduate degree in Software Engineering.</li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Projects and Publications -->
    <section id="publications" class="section">
        <div class="container">
            <h2>Featured Publication</h2>
            <hr>
            <div class="featured-project retro-box">
                <h3>Navigating the Handover</h3>
                <p><strong>IEEE Review</strong> | August 2024</p>
                <p class="featured-subtitle">Published in IEEE Open Journal of Vehicular Technology</p>
                <hr class="dotted">
                <p><strong>Tags:</strong> First Author | Review Paper | Machine Learning | Autonomous Vehicles |
                    Human-AI Interaction</p>
                <p class="featured-description">
                    A comprehensive review of takeover requests in Level 3 autonomous vehicles, analyzing
                    human-centered design approaches and exploring the Operational Design Domain (ODD)
                    concept for safe autonomous operation.
                </p>
                <ul class="featured-highlights">
                    <li>First-authored comprehensive review paper</li>
                    <li>Published in prestigious IEEE journal</li>
                    <li>Identified key research gaps in AV handovers</li>
                </ul>
                <div class="featured-actions">
                    <a href="https://doi.org/10.1109/ojvt.2024.3443630" class="btn primary" target="_blank"
                        rel="noopener">
                        Read Paper
                    </a>
                </div>
            </div>

            <div class="featured-project retro-box">
                <h3>At the Heart of Intersections: Analyzing Their Influence on Driver Heart Behaviour</h3>
                <p><strong>Springer Nature</strong> | 2025</p>
                <p class="featured-subtitle">Published in Data Science for Transportation</p>
                <hr class="dotted">
                <p><strong>Tags:</strong> First Author | Signal Processing | Statistical Analysis | Machine Learning |
                    Data Science | Transportation</p>
                <p class="featured-description">
                    This paper investigates the physiological impact of intersections on driver heart rate, addressing a
                    gap in prior research. Using video and heart rate data from the Honda Research Institute, we apply
                    E-Tests to analyze Poisson distributions of HR events occurring within and outside intersections.
                    Our findings support the hypothesis that intersections significantly influence driver heart rate,
                    indicating heightened stress or cognitive load at these critical road junctures. This research has
                    implications for urban traffic design and vehicle technology development in automated driving
                    environments.
                </p>
                <ul class="featured-highlights">
                    <li>First-authored research paper investigating driver physiology at intersections</li>
                    <li>Utilized statistical analysis (E-Tests) on real-world driving data from Honda Research Institute
                    </li>
                    <li>Found significant evidence that intersections influence driver heart rate and stress levels</li>
                    <li>Open-source code available for reproducibility and further research</li>
                </ul>
                <div class="featured-actions">
                    <a href="https://doi.org/10.1007/s42421-025-00125-5" class="btn primary" target="_blank"
                        rel="noopener">
                        Read Paper
                    </a>
                    <a href="https://github.com/Joelmillr/Heart-and-Intersections" class="btn secondary" target="_blank"
                        rel="noopener">
                        View Code
                    </a>
                </div>
            </div>
        </div>
    </section>

    <!-- Research Projects -->
    <section id="projects" class="section">
        <div class="container">
            <h2>Research Projects</h2>
            <hr>
            <div class="featured-project retro-box">
                <h3>AiX Lab Simulation Environment</h3>
                <p><strong>Research Infrastructure</strong> | 2024</p>
                <p><strong>Tags:</strong> Computer Vision | Signal Processing | Data Collection | Machine Learning</p>
                <hr class="dotted">
                <div class="featured-image">
                    <img src="assets/sim_setup.png" alt="Simulation Setup with Triple Monitors">
                </div>
                <p class="featured-description">
                    A comprehensive simulation environment for autonomous driving research with integrated computer
                    vision and signal processing pipelines. Features multi-modal sensor data collection (video,
                    physiological signals, vehicle dynamics) and real-time processing capabilities for ML model training
                    and validation.
                </p>
                <ul class="featured-highlights">
                    <li>Built data collection infrastructure for ML model training with synchronized multi-modal sensors
                    </li>
                    <li>Developed signal processing pipelines for physiological and vehicle dynamics data</li>
                    <li>Created computer vision tools for driver behavior analysis and gaze tracking</li>
                    <li>Integrated triple-monitor setup with comprehensive data logging for ML datasets</li>
                </ul>
            </div>

            <div class="featured-project retro-box">
                <h3>Reinforcement Learning for Autonomous Driving</h3>
                <p><strong>Machine Learning Research</strong> | 2023</p>
                <p><strong>Tags:</strong> Deep Learning | Reinforcement Learning | Computer Vision | Autonomous Vehicles
                </p>
                <hr class="dotted">
                <div class="featured-image">
                    <img src="assets/carla_sim.png" alt="CARLA Simulator Environment">
                </div>
                <p class="featured-description">
                    Developed a deep reinforcement learning agent for autonomous navigation using computer vision-based
                    perception. Implemented DQN and PPO algorithms with CNN feature extractors for processing camera
                    inputs, trained on complex driving scenarios in the CARLA simulator, achieving robust navigation
                    capabilities in diverse environments.
                </p>
                <ul class="featured-highlights">
                    <li>Implemented deep RL agents (DQN, PPO) with CNN-based computer vision processing</li>
                    <li>Designed reward functions and state representations for autonomous driving tasks</li>
                    <li>Trained models on complex multi-agent scenarios with varying weather and traffic conditions</li>
                    <li>Integrated with CARLA simulator using OpenAI Gym interface for reproducible ML experiments</li>
                </ul>
            </div>
        </div>
    </section>

    <!-- Machine Learning Demo -->
    <section id="drawing" class="section">
        <div class="container">
            <h2>Machine Learning Demo: MNIST Digit Recognition</h2>
            <hr>
            <div class="drawing-container">
                <div class="drawing-area retro-box">
                    <p><strong>Interactive Deep Learning Demo - Draw a single digit (0-9) below</strong></p>
                    <p>This demonstrates a convolutional neural network (CNN) trained on the MNIST dataset for
                        handwritten digit classification. The model processes your drawing using computer vision
                        preprocessing techniques.</p>
                    <canvas id="drawingCanvas" width="280" height="280" aria-label="Drawing canvas for digit input"
                        role="img"></canvas>
                    <div class="drawing-controls">
                        <button id="clearBtn" class="btn secondary" aria-label="Clear canvas">Clear</button>
                        <button id="predictBtn" class="btn primary" aria-label="Predict digit">Predict</button>
                    </div>
                </div>
                <div class="prediction-area retro-box">
                    <h3>CNN Prediction</h3>
                    <div id="predictionResult" class="prediction-result" role="status" aria-live="polite"
                        aria-atomic="true">
                        <span class="prediction-number blink" aria-label="Predicted digit">-</span>
                    </div>
                    <p class="experiment-text">This CNN model demonstrates computer vision and deep learning
                        capabilities. The model uses image preprocessing, feature extraction, and classification. Try
                        different drawing styles to see how the model performs! ðŸ˜„</p>
                </div>
            </div>
        </div>
    </section>

    <!-- Contact -->
    <section id="contact" class="section">
        <div class="container">
            <h2>Get in Touch</h2>
            <hr>
            <div class="contact-content">
                <div class="contact-item retro-box">
                    <p><strong>Email:</strong> <a href="mailto:joelmiller0430@gmail.com"
                            aria-label="Email Joel Miller">joelmiller0430@gmail.com</a>
                    </p>
                </div>
                <div class="contact-item retro-box">
                    <p><strong>Phone:</strong> <a href="tel:9059337920" aria-label="Phone number">(905) 933-7920</a></p>
                </div>
                <div class="contact-item retro-box">
                    <p><strong>LinkedIn:</strong> <a href="https://www.linkedin.com/in/joelmillr/" target="_blank"
                            rel="noopener" aria-label="LinkedIn profile (opens in new tab)">LinkedIn Profile</a></p>
                </div>
                <div class="contact-item retro-box">
                    <p><strong>ORCID:</strong> <a href="https://orcid.org/0009-0004-5678-6601" target="_blank"
                            rel="noopener" aria-label="ORCID profile (opens in new tab)">ORCID Profile</a></p>
                </div>
                <div class="contact-item retro-box">
                    <p><strong>Resume:</strong> <a href="assets/Resume.pdf" target="_blank"
                            aria-label="Download resume PDF (opens in new tab)">Download Resume (PDF)</a>
                    </p>
                </div>
            </div>
        </div>
    </section>

    <!-- Footer -->
    <footer>
        <div class="container">
            <hr>
            <p>Checkout this website's <a href="https://github.com/Joelmillr/Personal_Website">source code!</a></p>
        </div>
    </footer>

    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.11.0/dist/tf.min.js"></script>
    <script src="script.js"></script>
</body>

</html>